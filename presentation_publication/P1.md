# Sparsity and Noise in Knowledge Graph Embeddings  
**Authors**: Jay Pujara, Eriq Augustine, Lise Getoor  
**Presented by**: Bhagyasha Patil  

---

# Background  
**Knowledge Graphs (KGs)**  
- Structured triples: (subject, predicate, object).  
  Example: "Albert Einstein, bornIn, Ulm."  
- **Applications**: Question answering, decision support, semantic search.  

**Embeddings**  
- Represent entities/relations in low-dimensional vectors.  
- **Purpose**: Link prediction, KG completion, error correction.  

**Challenges**  
- **Sparsity**: Incomplete data for many entities/relations.  
- **Noise**: Errors from automatic extraction.  

---

# Dataset Overview  
**Datasets**  
1. **Freebase**: 1B triples, 124M entities, highly curated.  
2. **WordNet**: 380K triples, small but precise.  
3. **NELL**: Noisy extractions, precision ~35–85%.  

**Benchmarks**  
- **FB15K**: Subset of Freebase.  
- **WN18**: Subset of WordNet.  
- **NELL165**: Noisy, real-world data.  

---

# Key Concepts  
**Sparsity**  
- Lack of observations per entity/relation → Hard to train embeddings.  

**Reliability**  
- High precision: Curated datasets (e.g., Freebase).  
- Low precision: Extracted datasets (e.g., NELL).  

**Diversity**  
- Distribution of facts across entities/relations.  

---

# Experimental Setup  
**Embedding Methods**  
- **TransE**, **TransH**, **HolE**, **STransE**.  

**Metrics**  
- **AUPRC**: Area under precision-recall curve.  
- **Hits@10**: Top 10 ranked triples.  

---

# Results  
1. Sparse and noisy data → Poor embedding performance.  
   - Example: TransE AUPRC = 0.726, PSL-KGI = 0.891.  
2. Sparsity hurts performance → Dense data is key.  
3. Noise harms embeddings → Clean triples improve results.  
4. Trade-off: Low-noise triples help; high-noise triples harm.  

---

# Recommendations  
- Combine embeddings with probabilistic reasoning.  
- Use confidence scores for optimization.  
- Explore open-world embedding models.  

---

# Conclusion  
**Key Takeaways**  
- Embeddings struggle with sparse/noisy real-world data.  
- Dense, high-quality datasets are essential.  
- Future work: Open-world assumptions and hybrid models.  

**Thank you! Questions?**
